{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c4bac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 14.0   memory length: 15   epsilon: 0.9851045463620021\n",
      "episode: 1   score: 26.0   memory length: 42   epsilon: 0.9588496310845509\n",
      "episode: 2   score: 25.0   memory length: 68   epsilon: 0.9342286880693633\n",
      "episode: 3   score: 46.0   memory length: 115   epsilon: 0.8913148576343527\n",
      "episode: 4   score: 37.0   memory length: 153   epsilon: 0.8580640336044925\n",
      "episode: 5   score: 14.0   memory length: 168   epsilon: 0.8452827805735033\n",
      "episode: 6   score: 19.0   memory length: 188   epsilon: 0.8285367691502946\n",
      "episode: 7   score: 9.0   memory length: 198   epsilon: 0.8202885863627752\n",
      "episode: 8   score: 34.0   memory length: 233   epsilon: 0.7920612314455105\n",
      "episode: 9   score: 20.0   memory length: 254   epsilon: 0.7755932297267324\n",
      "episode: 10   score: 11.0   memory length: 266   epsilon: 0.766337129875968\n",
      "episode: 11   score: 21.0   memory length: 288   epsilon: 0.7496535623221505\n",
      "episode: 12   score: 47.0   memory length: 336   epsilon: 0.7145029791340722\n",
      "episode: 13   score: 46.0   memory length: 383   epsilon: 0.6816822575233553\n",
      "episode: 14   score: 124.0   memory length: 508   epsilon: 0.6015448579979431\n",
      "episode: 15   score: 77.0   memory length: 586   epsilon: 0.5563858806683429\n",
      "episode: 16   score: 178.0   memory length: 765   epsilon: 0.46515585607821586\n",
      "episode: 17   score: 156.0   memory length: 922   epsilon: 0.39753936928566525\n",
      "episode: 18   score: 97.0   memory length: 1020   epsilon: 0.36041096100926434\n",
      "episode: 19   score: 16.0   memory length: 1037   epsilon: 0.35433274633890316\n",
      "episode: 20   score: 9.0   memory length: 1047   epsilon: 0.3508053214034905\n",
      "episode: 21   score: 11.0   memory length: 1059   epsilon: 0.3466187336940617\n",
      "episode: 22   score: 9.0   memory length: 1069   epsilon: 0.34316810267859194\n",
      "episode: 23   score: 11.0   memory length: 1081   epsilon: 0.3390726592138397\n",
      "episode: 24   score: 10.0   memory length: 1092   epsilon: 0.335361453123493\n",
      "episode: 25   score: 8.0   memory length: 1101   epsilon: 0.33235524492954527\n",
      "episode: 26   score: 11.0   memory length: 1113   epsilon: 0.32838884448265515\n",
      "episode: 27   score: 9.0   memory length: 1123   epsilon: 0.3251196941980479\n",
      "episode: 28   score: 13.0   memory length: 1137   epsilon: 0.3205974863526735\n",
      "episode: 29   score: 8.0   memory length: 1146   epsilon: 0.3177236235951741\n",
      "episode: 30   score: 8.0   memory length: 1155   epsilon: 0.3148755223844758\n",
      "episode: 31   score: 8.0   memory length: 1164   epsilon: 0.3120529517919121\n",
      "episode: 32   score: 12.0   memory length: 1177   epsilon: 0.30802051452442963\n",
      "episode: 33   score: 8.0   memory length: 1186   epsilon: 0.30525939279728115\n",
      "episode: 34   score: 13.0   memory length: 1200   epsilon: 0.3010134290933992\n",
      "episode: 35   score: 15.0   memory length: 1216   epsilon: 0.29623316781840775\n",
      "episode: 36   score: 23.0   memory length: 1240   epsilon: 0.2892047357043746\n",
      "episode: 37   score: 10.0   memory length: 1251   epsilon: 0.28603934224861294\n",
      "episode: 38   score: 12.0   memory length: 1264   epsilon: 0.2823430602649749\n",
      "episode: 39   score: 19.0   memory length: 1284   epsilon: 0.2767495237336227\n",
      "episode: 40   score: 24.0   memory length: 1309   epsilon: 0.2699131774597243\n",
      "episode: 41   score: 36.0   memory length: 1346   epsilon: 0.2601040725539001\n",
      "episode: 42   score: 44.0   memory length: 1391   epsilon: 0.248653239882542\n",
      "episode: 43   score: 24.0   memory length: 1416   epsilon: 0.24251093608728802\n",
      "episode: 44   score: 47.0   memory length: 1464   epsilon: 0.23113981579733764\n",
      "episode: 45   score: 27.0   memory length: 1492   epsilon: 0.2247545193013052\n",
      "episode: 46   score: 35.0   memory length: 1528   epsilon: 0.21680336036122028\n",
      "episode: 47   score: 59.0   memory length: 1588   epsilon: 0.2041715862239982\n",
      "episode: 48   score: 33.0   memory length: 1622   epsilon: 0.197343080201605\n",
      "episode: 49   score: 42.0   memory length: 1665   epsilon: 0.18903311730874942\n",
      "episode: 50   score: 31.0   memory length: 1697   epsilon: 0.18307688713652753\n",
      "episode: 51   score: 39.0   memory length: 1737   epsilon: 0.175894819435018\n",
      "episode: 52   score: 55.0   memory length: 1793   epsilon: 0.16631077570238512\n",
      "episode: 53   score: 32.0   memory length: 1826   epsilon: 0.16090943156833393\n",
      "episode: 54   score: 24.0   memory length: 1851   epsilon: 0.15693460054388708\n",
      "episode: 55   score: 23.0   memory length: 1875   epsilon: 0.15321116810589017\n",
      "episode: 56   score: 40.0   memory length: 1916   epsilon: 0.1470535255419077\n",
      "episode: 57   score: 22.0   memory length: 1939   epsilon: 0.14370823986183776\n",
      "episode: 58   score: 30.0   memory length: 1970   epsilon: 0.13931946728658592\n",
      "episode: 59   score: 39.0   memory length: 2000   epsilon: 0.13385399394453418\n",
      "episode: 60   score: 61.0   memory length: 2000   epsilon: 0.12580317567624627\n",
      "episode: 61   score: 25.0   memory length: 2000   epsilon: 0.12257285392501287\n",
      "episode: 62   score: 45.0   memory length: 2000   epsilon: 0.11705952472752763\n",
      "episode: 63   score: 44.0   memory length: 2000   epsilon: 0.11190609126882678\n",
      "episode: 64   score: 26.0   memory length: 2000   epsilon: 0.1089235804722376\n",
      "episode: 65   score: 23.0   memory length: 2000   epsilon: 0.10633925814059424\n",
      "episode: 66   score: 32.0   memory length: 2000   epsilon: 0.10288563388954207\n",
      "episode: 67   score: 27.0   memory length: 2000   epsilon: 0.10004339195341891\n",
      "episode: 68   score: 20.0   memory length: 2000   epsilon: 0.09796335737372537\n",
      "episode: 69   score: 27.0   memory length: 2000   epsilon: 0.09525709458459826\n",
      "episode: 70   score: 31.0   memory length: 2000   epsilon: 0.09225564600796458\n",
      "episode: 71   score: 37.0   memory length: 2000   epsilon: 0.08881401567397287\n",
      "episode: 72   score: 23.0   memory length: 2000   epsilon: 0.0867068131465305\n",
      "episode: 73   score: 23.0   memory length: 2000   epsilon: 0.08464960613452524\n",
      "episode: 74   score: 23.0   memory length: 2000   epsilon: 0.0826412084436871\n",
      "episode: 75   score: 18.0   memory length: 2000   epsilon: 0.08108507736992851\n",
      "episode: 76   score: 23.0   memory length: 2000   epsilon: 0.0791612517363822\n",
      "episode: 77   score: 13.0   memory length: 2000   epsilon: 0.07806016915036741\n",
      "episode: 78   score: 19.0   memory length: 2000   epsilon: 0.07651370858790009\n",
      "episode: 79   score: 12.0   memory length: 2000   epsilon: 0.07552497661721554\n",
      "episode: 80   score: 13.0   memory length: 2000   epsilon: 0.0744744723018047\n",
      "episode: 81   score: 14.0   memory length: 2000   epsilon: 0.07336514125241882\n",
      "episode: 82   score: 14.0   memory length: 2000   epsilon: 0.07227233419224825\n",
      "episode: 83   score: 10.0   memory length: 2000   epsilon: 0.07148130159339547\n",
      "episode: 84   score: 9.0   memory length: 2000   epsilon: 0.0707696966732701\n",
      "episode: 85   score: 23.0   memory length: 2000   epsilon: 0.06909061390052766\n",
      "episode: 86   score: 15.0   memory length: 2000   epsilon: 0.06799341638648719\n",
      "episode: 87   score: 12.0   memory length: 2000   epsilon: 0.06711478606235186\n",
      "episode: 88   score: 13.0   memory length: 2000   epsilon: 0.06618126214027624\n",
      "episode: 89   score: 17.0   memory length: 2000   epsilon: 0.06500007135289768\n",
      "episode: 90   score: 12.0   memory length: 2000   epsilon: 0.06416012188724667\n",
      "episode: 91   score: 13.0   memory length: 2000   epsilon: 0.06326769546172861\n",
      "episode: 92   score: 19.0   memory length: 2000   epsilon: 0.062014290595012456\n",
      "episode: 93   score: 13.0   memory length: 2000   epsilon: 0.06115171131587699\n",
      "episode: 94   score: 7.0   memory length: 2000   epsilon: 0.060664206453048174\n",
      "episode: 95   score: 13.0   memory length: 2000   epsilon: 0.05982040598432518\n",
      "episode: 96   score: 10.0   memory length: 2000   epsilon: 0.05916566179017289\n",
      "episode: 97   score: 8.0   memory length: 2000   epsilon: 0.058635295835417614\n",
      "episode: 98   score: 7.0   memory length: 2000   epsilon: 0.05816785197754229\n",
      "episode: 99   score: 7.0   memory length: 2000   epsilon: 0.0577041346082461\n",
      "episode: 100   score: 8.0   memory length: 2000   epsilon: 0.057186869905733934\n",
      "episode: 101   score: 8.0   memory length: 2000   epsilon: 0.05667424200740021\n",
      "episode: 102   score: 9.0   memory length: 2000   epsilon: 0.056110043139194835\n",
      "episode: 103   score: 8.0   memory length: 2000   epsilon: 0.055607068006314264\n",
      "episode: 104   score: 8.0   memory length: 2000   epsilon: 0.05510860158471143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 105   score: 8.0   memory length: 2000   epsilon: 0.05461460345792028\n",
      "episode: 106   score: 9.0   memory length: 2000   epsilon: 0.0540709085381996\n",
      "episode: 107   score: 86.0   memory length: 2000   epsilon: 0.04956340590351174\n",
      "episode: 108   score: 31.0   memory length: 2000   epsilon: 0.048001716301798183\n",
      "episode: 109   score: 24.0   memory length: 2000   epsilon: 0.04681596410987613\n",
      "episode: 110   score: 22.0   memory length: 2000   epsilon: 0.0457509588761811\n",
      "episode: 111   score: 27.0   memory length: 2000   epsilon: 0.04448707694223361\n",
      "episode: 112   score: 40.0   memory length: 2000   epsilon: 0.04269911643052126\n",
      "episode: 113   score: 25.0   memory length: 2000   epsilon: 0.041602706234017746\n",
      "episode: 114   score: 28.0   memory length: 2000   epsilon: 0.04041296741885872\n",
      "episode: 115   score: 20.0   memory length: 2000   epsilon: 0.039572728318025406\n",
      "episode: 116   score: 14.0   memory length: 2000   epsilon: 0.03898327457803516\n",
      "episode: 117   score: 11.0   memory length: 2000   epsilon: 0.03851803962216637\n",
      "episode: 118   score: 27.0   memory length: 2000   epsilon: 0.037453968931510845\n",
      "episode: 119   score: 26.0   memory length: 2000   epsilon: 0.03645574921490045\n",
      "episode: 120   score: 11.0   memory length: 2000   epsilon: 0.036020678301521745\n",
      "episode: 121   score: 9.0   memory length: 2000   epsilon: 0.03566208813410397\n",
      "episode: 122   score: 10.0   memory length: 2000   epsilon: 0.03527176070698369\n",
      "episode: 123   score: 8.0   memory length: 2000   epsilon: 0.034955581685618194\n",
      "episode: 124   score: 9.0   memory length: 2000   epsilon: 0.03460759468259993\n",
      "episode: 125   score: 9.0   memory length: 2000   epsilon: 0.03426307193188217\n",
      "episode: 126   score: 8.0   memory length: 2000   epsilon: 0.03395593488129956\n",
      "episode: 127   score: 9.0   memory length: 2000   epsilon: 0.03361789948196624\n",
      "episode: 128   score: 8.0   memory length: 2000   epsilon: 0.03331654581133795\n",
      "episode: 129   score: 8.0   memory length: 2000   epsilon: 0.03301789350028896\n",
      "episode: 130   score: 9.0   memory length: 2000   epsilon: 0.032689196415271814\n",
      "episode: 131   score: 18.0   memory length: 2000   epsilon: 0.032073659986461445\n",
      "episode: 132   score: 24.0   memory length: 2000   epsilon: 0.031281367219411264\n",
      "episode: 133   score: 15.0   memory length: 2000   epsilon: 0.030784601647197075\n",
      "episode: 134   score: 15.0   memory length: 2000   epsilon: 0.030295724989556416\n",
      "episode: 135   score: 18.0   memory length: 2000   epsilon: 0.029725257544245307\n",
      "episode: 136   score: 11.0   memory length: 2000   epsilon: 0.02937050979584611\n",
      "episode: 137   score: 13.0   memory length: 2000   epsilon: 0.02896198471357129\n",
      "episode: 138   score: 37.0   memory length: 2000   epsilon: 0.02788154736977743\n",
      "episode: 139   score: 39.0   memory length: 2000   epsilon: 0.026787760142101585\n",
      "episode: 140   score: 21.0   memory length: 2000   epsilon: 0.026204576333666588\n",
      "episode: 141   score: 11.0   memory length: 2000   epsilon: 0.025891845167644353\n",
      "episode: 142   score: 61.0   memory length: 2000   epsilon: 0.024334547294547412\n",
      "episode: 143   score: 40.0   memory length: 2000   epsilon: 0.023356528224210547\n",
      "episode: 144   score: 46.0   memory length: 2000   epsilon: 0.02228364520898687\n",
      "episode: 145   score: 39.0   memory length: 2000   epsilon: 0.021409462503400374\n",
      "episode: 146   score: 40.0   memory length: 2000   epsilon: 0.020549004227331292\n",
      "episode: 147   score: 29.0   memory length: 2000   epsilon: 0.019941390048622342\n",
      "episode: 148   score: 48.0   memory length: 2000   epsilon: 0.018987349798119973\n",
      "episode: 149   score: 49.0   memory length: 2000   epsilon: 0.01806087399251748\n",
      "episode: 150   score: 47.0   memory length: 2000   epsilon: 0.017214015809443074\n",
      "episode: 151   score: 79.0   memory length: 2000   epsilon: 0.015889903347743102\n",
      "episode: 152   score: 110.0   memory length: 2000   epsilon: 0.01421970048080217\n",
      "episode: 153   score: 47.0   memory length: 2000   epsilon: 0.013552951478620824\n",
      "episode: 154   score: 44.0   memory length: 2000   epsilon: 0.012956295770538579\n",
      "episode: 155   score: 104.0   memory length: 2000   epsilon: 0.01166425800589929\n",
      "episode: 156   score: 113.0   memory length: 2000   epsilon: 0.01040693339733582\n",
      "episode: 157   score: 81.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 158   score: 80.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 159   score: 42.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 160   score: 74.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 161   score: 120.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 162   score: 21.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 163   score: 44.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 164   score: 55.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 165   score: 23.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 166   score: 36.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 167   score: 49.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 168   score: 27.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 169   score: 32.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 170   score: 18.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 171   score: 29.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 172   score: 30.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 173   score: 25.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 174   score: 29.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 175   score: 23.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 176   score: 23.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 177   score: 27.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 178   score: 65.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 179   score: 76.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 180   score: 166.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 181   score: 209.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 182   score: 224.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 183   score: 175.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 184   score: 90.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 185   score: 160.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 186   score: 136.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 187   score: 71.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 188   score: 89.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 189   score: 83.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 190   score: 86.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 191   score: 104.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 192   score: 137.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 193   score: 104.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 194   score: 121.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 195   score: 121.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 196   score: 106.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 197   score: 126.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 198   score: 147.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 199   score: 83.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 200   score: 91.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 201   score: 338.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 202   score: 230.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 203   score: 87.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 204   score: 84.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 205   score: 76.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 206   score: 114.0   memory length: 2000   epsilon: 0.009998671593271896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 207   score: 100.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 208   score: 91.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 209   score: 101.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 210   score: 64.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 211   score: 77.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 212   score: 191.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 213   score: 75.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 214   score: 142.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 215   score: 48.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 216   score: 62.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 217   score: 161.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 218   score: 68.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 219   score: 96.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 220   score: 138.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 221   score: 65.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 222   score: 97.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 223   score: 75.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 224   score: 106.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 225   score: 375.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 226   score: 236.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 227   score: 320.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 228   score: 389.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 229   score: 495.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 230   score: 293.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 231   score: 190.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 232   score: 187.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 233   score: 126.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 234   score: 489.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 235   score: 196.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 236   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 237   score: 221.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 238   score: 212.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 239   score: 242.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 240   score: 221.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 241   score: 225.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 242   score: 224.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 243   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 244   score: 108.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 245   score: 115.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 246   score: 102.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 247   score: 110.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 248   score: 92.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 249   score: 318.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 250   score: 487.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 251   score: 251.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 252   score: 318.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 253   score: 374.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 254   score: 288.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 255   score: 437.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 256   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 257   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 258   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 259   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 260   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 261   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 262   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 263   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 264   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "EPISODES = 500\n",
    "\n",
    "\n",
    "# DRQN Agent for the Cartpole\n",
    "# it uses Neural Network to approximate q function\n",
    "# and replay memory & target q network\n",
    "class DRQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # if you want to see Cartpole learning, then change to True\n",
    "        self.render = False\n",
    "        self.load_model = False\n",
    "\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # These are hyper parameters for the DRQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        # initialize target model\n",
    "        self.update_target_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./cartpole_drqn.h5\")\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(32, input_shape=(self.state_size, 2)))\n",
    "        model.add(Dense(self.action_size))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # after some time interval update the target model to be same with model\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size)\n",
    "    def train_model(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        update_input = np.zeros((batch_size, self.state_size, 2))\n",
    "        update_target = np.zeros((batch_size, self.state_size, 2))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            update_input[i] = mini_batch[i][0]\n",
    "            action.append(mini_batch[i][1])\n",
    "            reward.append(mini_batch[i][2])\n",
    "            update_target[i] = mini_batch[i][3]\n",
    "            done.append(mini_batch[i][4])\n",
    "\n",
    "        target = self.model.predict(update_input)\n",
    "        target_val = self.target_model.predict(update_target)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # Q Learning: get maximum Q value at s' from target model\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                target[i][action[i]] = reward[i] + self.discount_factor * (\n",
    "                    np.amax(target_val[i]))\n",
    "\n",
    "        # and do the model fit!      \n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size,\n",
    "                       epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # In case of CartPole-v1, maximum length of episode is 500\n",
    "    env = gym.make('CartPole-v1')\n",
    "\n",
    "    # Number of past state to use\n",
    "    number_of_past_state = 4\n",
    "\n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    expanded_state_size = state_size * number_of_past_state\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = DRQNAgent(expanded_state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "\n",
    "        # expand the state with past states and initialize\n",
    "        expanded_state = np.zeros(expanded_state_size)\n",
    "        expanded_next_state = np.zeros(expanded_state_size)\n",
    "        for h in range(state_size):\n",
    "            expanded_state[(h + 1) * number_of_past_state - 1] = state[h]\n",
    "\n",
    "        # reshape states for LSTM input without embedding layer\n",
    "        reshaped_state = np.zeros((1, expanded_state_size, 2))\n",
    "        for i in range(expanded_state_size):\n",
    "            for j in range(2):\n",
    "                reshaped_state[0, i, j] = expanded_state[i]\n",
    "\n",
    "        while not done:\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "\n",
    "            # get action for the current state and go one step in environment\n",
    "            action = agent.get_action(reshaped_state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # update the expanded next state with next state values\n",
    "            for h in range(state_size):\n",
    "                expanded_next_state[(h + 1) * number_of_past_state - 1] = next_state[h]\n",
    "\n",
    "            # reshape expanded next state for LSTM input without embedding layer\n",
    "            reshaped_next_state = np.zeros((1, expanded_state_size, 2))\n",
    "            for i in range(expanded_state_size):\n",
    "                for j in range(2):\n",
    "                    reshaped_next_state[0, i, j] = expanded_next_state[i]\n",
    "\n",
    "            # if an action make the episode end, then gives penalty of -100\n",
    "            reward = reward if not done or score == 499 else -100\n",
    "\n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            agent.append_sample(reshaped_state, action, reward, reshaped_next_state, done)\n",
    "\n",
    "            # every time step do the training\n",
    "            agent.train_model()\n",
    "            score += reward\n",
    "            reshaped_state = reshaped_next_state\n",
    "\n",
    "            # Shifting past state elements to the left by one\n",
    "            expanded_next_state = np.roll(expanded_next_state, -1)\n",
    "\n",
    "            if done:\n",
    "                # every episode update the target model to be same with model\n",
    "                agent.update_target_model()\n",
    "\n",
    "                # every episode, plot the play time\n",
    "                score = score if score == 500 else score + 100\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./cartpole_drqn.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "            # if the mean of scores of last 10 episode is bigger than 490\n",
    "            # stop training\n",
    "            # revised to exit cleanly on Jupiter notebook\n",
    "            if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
    "                #sys.exit()\n",
    "                env.close()\n",
    "                break\n",
    "\n",
    "        # save the model\n",
    "        if e % 50 == 0:\n",
    "            agent.model.save_weights(\"./cartpole_drqn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
